{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "\n",
    "yt_dlp_path = r\"C:\\Users\\Lenovo\\pyannote_env\\Scripts\\yt-dlp.exe\"  # Update this path as needed\n",
    "video_url = \"https://www.youtube.com/watch?v=awbVzXKr5co\"\n",
    "output_audio = \"D:/whisper_med/audio_file_patient/youtube_audio.wav\"\n",
    "\n",
    "command = [\n",
    "    yt_dlp_path,  # Use full path\n",
    "    \"-x\",\n",
    "    \"--audio-format\", \"wav\",\n",
    "    \"-o\", output_audio,\n",
    "    video_url,\n",
    "]\n",
    "\n",
    "subprocess.run(command)\n",
    "\n",
    "print(f\"Audio extracted and saved as {output_audio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "# Define the path to your audio file\n",
    "audio_path = \"D:/whisper_med/audio_file_patient/youtube_audio.wav\"\n",
    "processed_audio_path = \"D:/whisper_med/audio_file_patient/processed_audio.wav\"\n",
    "\n",
    "# Convert audio to mono, 16kHz (PyAnnote requires this format)\n",
    "ffmpeg_command = [\n",
    "    \"ffmpeg\", \"-i\", audio_path, \n",
    "    \"-ar\", \"16000\", \"-ac\", \"1\", processed_audio_path, \"-y\"\n",
    "]\n",
    "\n",
    "subprocess.run(ffmpeg_command, check=True)\n",
    "\n",
    "# Load the pre-trained speaker diarization pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "\n",
    "# Perform speaker diarization, specifying that we expect 2 speakers\n",
    "diarization = pipeline({\"uri\": \"youtube_audio\", \"audio\": processed_audio_path}, num_speakers=2)\n",
    "\n",
    "# Print speaker segments\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"Speaker: {speaker}, Start: {turn.start:.2f}s, End: {turn.end:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Path where segmented audio files are stored\n",
    "SEGMENTS_DIR = \"D:/whisper_med/audio_file_patient/segments\"\n",
    "TRANSCRIPTIONS_DIR = \"D:/whisper_med/audio_file_patient/transcriptions\"\n",
    "\n",
    "# Ensure transcription directory exists\n",
    "os.makedirs(TRANSCRIPTIONS_DIR, exist_ok=True)\n",
    "\n",
    "# Load Whisper model with GPU support if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "whisper_model = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"D:/whisper_medical_model\",  # Path to the saved Whisper model\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"Whisper model loaded successfully!\")\n",
    "\n",
    "# Process each segment in the directory\n",
    "for segment_file in sorted(os.listdir(SEGMENTS_DIR)):  \n",
    "    segment_path = os.path.join(SEGMENTS_DIR, segment_file)\n",
    "\n",
    "    if segment_file.endswith(\".wav\"):  # Ensure it's an audio file\n",
    "        print(f\"Transcribing {segment_file}...\")\n",
    "\n",
    "        # Transcribe the audio\n",
    "        transcription_result = whisper_model(segment_path, return_timestamps=True)\n",
    "        transcription_text = transcription_result[\"text\"]\n",
    "\n",
    "        # Define transcription file path (same name as segment but .txt)\n",
    "        transcript_filename = os.path.splitext(segment_file)[0] + \".txt\"\n",
    "        transcript_path = os.path.join(TRANSCRIPTIONS_DIR, transcript_filename)\n",
    "\n",
    "        # Save transcription\n",
    "        with open(transcript_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(transcription_text)\n",
    "\n",
    "        print(f\"Saved transcription: {transcript_path}\")\n",
    "\n",
    "print(\"\\nAll transcriptions saved in:\", TRANSCRIPTIONS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Input   Output\n",
      "0    You need to take these antibiotics twice a day.   Doctor\n",
      "1  I have been feeling unwell for the past two days.  Patient\n",
      "2  Let's schedule a follow-up appointment in two ...   Doctor\n",
      "3  I've had a persistent dry cough for three week...  Patient\n",
      "4  Avoid caffeine and alcohol until your heart rh...   Doctor\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset from Excel file\n",
    "dataset_path = r\"C:\\Users\\Lenovo\\Desktop\\fixed_doctor_patient_dialogue.xlsx\"\n",
    "df = pd.read_excel(dataset_path)\n",
    "\n",
    "# Check dataset structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"YourTextColumn\": \"Input\", \"YourLabelColumn\": \"Output\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical labels to numerical values\n",
    "label_mapping = {\"Doctor\": 1, \"Patient\": 0}\n",
    "df[\"label\"] = df[\"Output\"].map(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Input', 'Output', 'label'],\n",
      "    num_rows: 392\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Verify dataset structure\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved at: C:\\Users\\Lenovo\\Desktop\\cleaned_doctor_patient_dialogue.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BioGptForSequenceClassification were not initialized from the model checkpoint at microsoft/biogpt and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397230d02d6c42f88e55efea409a7c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/361 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13736\\438780397.py:74: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 40:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.169742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model saved at: D:\\fine_tuned_biogpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 04:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics: {'eval_loss': 0.169741690158844, 'eval_runtime': 35.96, 'eval_samples_per_second': 2.03, 'eval_steps_per_second': 0.278, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import BioGptTokenizer, BioGptForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# 1. Load and preprocess the dataset from Excel\n",
    "excel_file = r\"C:\\Users\\Lenovo\\Desktop\\doctor_patient_dialogue.xlsx\"\n",
    "df = pd.read_excel(excel_file, header=None)\n",
    "df.columns = [\"Raw\"]\n",
    "\n",
    "# If the first row contains headers like \"Input,Output\", remove it\n",
    "if \"Input\" in df.iloc[0, 0]:\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# Split the raw column by comma into Input and Output\n",
    "df[['Input', 'Output']] = df['Raw'].str.split(',', n=1, expand=True)\n",
    "df['Input'] = df['Input'].str.strip()\n",
    "df['Output'] = df['Output'].str.strip()\n",
    "\n",
    "# Convert Output to labels (e.g., 1 for Doctor, 0 for Patient)\n",
    "label_mapping = {\"Doctor\": 1, \"Patient\": 0}\n",
    "df['label'] = df['Output'].map(label_mapping)\n",
    "\n",
    "# If any rows didn't match, they will be NaN; drop or handle them as needed.\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "# Drop the raw column now that we have Input and Output\n",
    "df = df.drop(columns=[\"Raw\"])\n",
    "\n",
    "# Save the cleaned dataset (optional)\n",
    "cleaned_file = r\"C:\\Users\\Lenovo\\Desktop\\cleaned_doctor_patient_dialogue.xlsx\"\n",
    "df.to_excel(cleaned_file, index=False)\n",
    "print(\"Cleaned dataset saved at:\", cleaned_file)\n",
    "\n",
    "# 2. Convert DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 3. Load BioGPT tokenizer and model for sequence classification\n",
    "model_name = \"microsoft/biogpt\"  # or your chosen variant\n",
    "tokenizer = BioGptTokenizer.from_pretrained(model_name)\n",
    "model = BioGptForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# 4. Tokenization function with proper padding and truncation\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Input\"], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "# Remove original text columns to avoid nesting issues\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"Input\", \"Output\"])\n",
    "# Set dataset format for PyTorch\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# 5. Split dataset into train and test sets\n",
    "split_dataset = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "# 6. Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# 7. Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 8. Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# 9. Save the fine-tuned model and tokenizer\n",
    "save_dir = r\"D:\\fine_tuned_biogpt\"\n",
    "\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(\"Fine-tuning complete. Model saved at:\", save_dir)\n",
    "\n",
    "# 10. Evaluate the model\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Evaluation Metrics:\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.169741690158844, 'eval_runtime': 33.8246, 'eval_samples_per_second': 2.158, 'eval_steps_per_second': 0.296, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: segment_0.txt\n",
      "Text: May I come in, Doctor? Yes, come in. Take your seat.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_1.txt\n",
      "Text: Thank you, doctor. Um, what's your name?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_10.txt\n",
      "Text: Hmm, any other symptoms?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_11.txt\n",
      "Text: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_12.txt\n",
      "Text: Do you have a headache? No.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_13.txt\n",
      "Text: Did you have this kind of a stomach ache before?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_14.txt\n",
      "Text: Yes, doctor. I had it once before.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_15.txt\n",
      "Text: How many days ago?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_16.txt\n",
      "Text: almost three months ago. But at that time the pain stopped after I took an antacid.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_17.txt\n",
      "Text: Hmm. Um, please lie on that bed. I have to check. Okay, doctor.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_18.txt\n",
      "Text: Does it hurt here? Yes, doctor, it hurts a lot. Okay, you can get it now.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_19.txt\n",
      "Text: Is it something serious, doctor?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_2.txt\n",
      "Text: Simran Parveen.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_20.txt\n",
      "Text: I can't say now, I'm writing down some tests. Try to do this by today.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_21.txt\n",
      "Text: But what about now? I can't even work properly because of the pain. Hmm, I understand. I'm giving you an injection for temporary relief.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_22.txt\n",
      "Text: Injection? Don't you have any medicine?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_23.txt\n",
      "Text: Why? Are you scared of injections? It's not like that. I mean, it would be better if you could give me some medicine.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_24.txt\n",
      "Text: Nothing will happen. You won't even feel it. Look at that side.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_25.txt\n",
      "Text: Please, doctor, be careful.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_26.txt\n",
      "Text: You can open your eyes now. It's already done.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_27.txt\n",
      "Text: Oh, it's done. Thank you so much. I did not feel anything at all.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_28.txt\n",
      "Text: After receiving the test reports, bring them to me as soon as possible.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_29.txt\n",
      "Text: There's nothing to fear, right? Don't be so scared beforehand. Let's see the repose first.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_3.txt\n",
      "Text: Thank you.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_30.txt\n",
      "Text: Won't you give me any medicines doctor? Hmm, I'm prescribing this medicine. It's just for today. Take it after your dinner.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_31.txt\n",
      "Text: Okay, doctor. Um, where shall I submit the fees? Please submit that in the cash counter.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_32.txt\n",
      "Text: Thank you, Doctor.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_33.txt\n",
      "Text: Welcome.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_34.txt\n",
      "Text: May I come in, doctor? Oh yes, come in please. Here are the reports of the test that you gave. Oh yeah, let me check them.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_35.txt\n",
      "Text: I'm sorry.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_36.txt\n",
      "Text: Hmm, it's not that serious, nothing to worry about. It was just food poisoning. I'm writing down a medicines, please take them for one week after dinner. Oh, okay doctor. And if you face this problem again, come back immediately. Sure, doctor, thank you. You're welcome.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_37.txt\n",
      "Text: So, this was the conversation. I hope you liked it. Now is the time for the question. The question is, what was the age of the patient? Make sure to answer this question in the comment box below. I'd eagerly be waiting for your answers. And if you like this conversation, then click on the like button. And if you want more such conversations like this and haven't subscribed my channel yet, then make sure to click on the subscribe button and share this video with your friends and family. That's it for today. Meet you in the next video with another interesting topic. Thank you. Bye.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_4.txt\n",
      "Text: Hmm. And how old are you?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_5.txt\n",
      "Text: I'm 29.\n",
      "Predicted Role: Patient\n",
      "\n",
      "File: segment_6.txt\n",
      "Text: Oops!\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_7.txt\n",
      "Text: Okay.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_8.txt\n",
      "Text: Now tell me, what are the problems that you're facing?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "File: segment_9.txt\n",
      "Text: Since yesterday night I've been having severe stomach ache. I took an antithecid last night but the pain was still the same.\n",
      "Predicted Role: Patient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# from transformers import BioGptTokenizer, BioGptForSequenceClassification\n",
    "\n",
    "# # Define model path and transcriptions directory\n",
    "# model_path = r\"D:\\fine_tuned_biogpt\"\n",
    "# transcriptions_dir = r\"D:\\whisper_med\\audio_file_patient\\transcriptions\"\n",
    "\n",
    "# # Load fine-tuned BioGPT model and tokenizer\n",
    "# tokenizer = BioGptTokenizer.from_pretrained(model_path)\n",
    "# model = BioGptForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "# model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# def predict_role(text):\n",
    "#     \"\"\"\n",
    "#     Tokenize the input text and predict the role using the fine-tuned model.\n",
    "#     Returns \"Doctor\" if predicted label == 1, otherwise \"Patient\".\n",
    "#     \"\"\"\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "#     inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "#     return \"Doctor\" if predicted_label == 1 else \"Patient\"\n",
    "\n",
    "# # Process each transcribed text file\n",
    "# for filename in sorted(os.listdir(transcriptions_dir)):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         file_path = os.path.join(transcriptions_dir, filename)\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             text = f.read().strip()\n",
    "#         # Preprocess the text if needed (here we simply strip extra whitespace)\n",
    "#         text = text.replace(\"\\n\", \" \").strip()\n",
    "#         role = predict_role(text)\n",
    "#         print(f\"File: {filename}\")\n",
    "#         print(f\"Text: {text}\")\n",
    "#         print(f\"Predicted Role: {role}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: segment_0.txt\n",
      "Full Text: May I come in, Doctor? Yes, come in. Take your seat.\n",
      "\n",
      "Sentence: May I come in, Doctor?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Yes, come in.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Take your seat.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_1.txt\n",
      "Full Text: Thank you, doctor. Um, what's your name?\n",
      "\n",
      "Sentence: Thank you, doctor.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Um, what's your name?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_10.txt\n",
      "Full Text: Hmm, any other symptoms?\n",
      "\n",
      "Sentence: Hmm, any other symptoms?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_11.txt\n",
      "Full Text: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "\n",
      "Sentence: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "Predicted Role: Patient\n",
      "\n",
      "\n",
      "File: segment_12.txt\n",
      "Full Text: Do you have a headache? No.\n",
      "\n",
      "Sentence: Do you have a headache?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_13.txt\n",
      "Full Text: Did you have this kind of a stomach ache before?\n",
      "\n",
      "Sentence: Did you have this kind of a stomach ache before?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_14.txt\n",
      "Full Text: Yes, doctor. I had it once before.\n",
      "\n",
      "Sentence: I had it once before.\n",
      "Predicted Role: Patient\n",
      "\n",
      "\n",
      "File: segment_15.txt\n",
      "Full Text: How many days ago?\n",
      "\n",
      "Sentence: How many days ago?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_16.txt\n",
      "Full Text: almost three months ago. But at that time the pain stopped after I took an antacid.\n",
      "\n",
      "Sentence: almost three months ago.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: But at that time the pain stopped after I took an antacid.\n",
      "Predicted Role: Patient\n",
      "\n",
      "\n",
      "File: segment_17.txt\n",
      "Full Text: Hmm. Um, please lie on that bed. I have to check. Okay, doctor.\n",
      "\n",
      "Sentence: Um, please lie on that bed.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: I have to check.\n",
      "Predicted Role: Patient\n",
      "\n",
      "\n",
      "File: segment_18.txt\n",
      "Full Text: Does it hurt here? Yes, doctor, it hurts a lot. Okay, you can get it now.\n",
      "\n",
      "Sentence: Does it hurt here?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Yes, doctor, it hurts a lot.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Okay, you can get it now.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_19.txt\n",
      "Full Text: Is it something serious, doctor?\n",
      "\n",
      "Sentence: Is it something serious, doctor?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_2.txt\n",
      "Full Text: Simran Parveen.\n",
      "\n",
      "\n",
      "File: segment_20.txt\n",
      "Full Text: I can't say now, I'm writing down some tests. Try to do this by today.\n",
      "\n",
      "Sentence: I can't say now, I'm writing down some tests.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: Try to do this by today.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_21.txt\n",
      "Full Text: But what about now? I can't even work properly because of the pain. Hmm, I understand. I'm giving you an injection for temporary relief.\n",
      "\n",
      "Sentence: But what about now?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: I can't even work properly because of the pain.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: Hmm, I understand.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: I'm giving you an injection for temporary relief.\n",
      "Predicted Role: Patient\n",
      "\n",
      "\n",
      "File: segment_22.txt\n",
      "Full Text: Injection? Don't you have any medicine?\n",
      "\n",
      "Sentence: Don't you have any medicine?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_23.txt\n",
      "Full Text: Why? Are you scared of injections? It's not like that. I mean, it would be better if you could give me some medicine.\n",
      "\n",
      "Sentence: Are you scared of injections?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: It's not like that.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: I mean, it would be better if you could give me some medicine.\n",
      "Predicted Role: Patient\n",
      "\n",
      "\n",
      "File: segment_24.txt\n",
      "Full Text: Nothing will happen. You won't even feel it. Look at that side.\n",
      "\n",
      "Sentence: Nothing will happen.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: You won't even feel it.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Look at that side.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_25.txt\n",
      "Full Text: Please, doctor, be careful.\n",
      "\n",
      "Sentence: Please, doctor, be careful.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_26.txt\n",
      "Full Text: You can open your eyes now. It's already done.\n",
      "\n",
      "Sentence: You can open your eyes now.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: It's already done.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_27.txt\n",
      "Full Text: Oh, it's done. Thank you so much. I did not feel anything at all.\n",
      "\n",
      "Sentence: Oh, it's done.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Thank you so much.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: I did not feel anything at all.\n",
      "Predicted Role: Patient\n",
      "\n",
      "\n",
      "File: segment_28.txt\n",
      "Full Text: After receiving the test reports, bring them to me as soon as possible.\n",
      "\n",
      "Sentence: After receiving the test reports, bring them to me as soon as possible.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_29.txt\n",
      "Full Text: There's nothing to fear, right? Don't be so scared beforehand. Let's see the repose first.\n",
      "\n",
      "Sentence: There's nothing to fear, right?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Don't be so scared beforehand.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Let's see the repose first.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_3.txt\n",
      "Full Text: Thank you.\n",
      "\n",
      "\n",
      "File: segment_30.txt\n",
      "Full Text: Won't you give me any medicines doctor? Hmm, I'm prescribing this medicine. It's just for today. Take it after your dinner.\n",
      "\n",
      "Sentence: Won't you give me any medicines doctor?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Hmm, I'm prescribing this medicine.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: It's just for today.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Take it after your dinner.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_31.txt\n",
      "Full Text: Okay, doctor. Um, where shall I submit the fees? Please submit that in the cash counter.\n",
      "\n",
      "Sentence: Um, where shall I submit the fees?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Please submit that in the cash counter.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_32.txt\n",
      "Full Text: Thank you, Doctor.\n",
      "\n",
      "Sentence: Thank you, Doctor.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_33.txt\n",
      "Full Text: Welcome.\n",
      "\n",
      "\n",
      "File: segment_34.txt\n",
      "Full Text: May I come in, doctor? Oh yes, come in please. Here are the reports of the test that you gave. Oh yeah, let me check them.\n",
      "\n",
      "Sentence: May I come in, doctor?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Oh yes, come in please.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Here are the reports of the test that you gave.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Oh yeah, let me check them.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_35.txt\n",
      "Full Text: I'm sorry.\n",
      "\n",
      "\n",
      "File: segment_36.txt\n",
      "Full Text: Hmm, it's not that serious, nothing to worry about. It was just food poisoning. I'm writing down a medicines, please take them for one week after dinner. Oh, okay doctor. And if you face this problem again, come back immediately. Sure, doctor, thank you. You're welcome.\n",
      "\n",
      "Sentence: Hmm, it's not that serious, nothing to worry about.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: It was just food poisoning.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: I'm writing down a medicines, please take them for one week after dinner.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: Oh, okay doctor.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: And if you face this problem again, come back immediately.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Sure, doctor, thank you.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_37.txt\n",
      "Full Text: So, this was the conversation. I hope you liked it. Now is the time for the question. The question is, what was the age of the patient? Make sure to answer this question in the comment box below. I'd eagerly be waiting for your answers. And if you like this conversation, then click on the like button. And if you want more such conversations like this and haven't subscribed my channel yet, then make sure to click on the subscribe button and share this video with your friends and family. That's it for today. Meet you in the next video with another interesting topic. Thank you. Bye.\n",
      "\n",
      "Sentence: So, this was the conversation.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: I hope you liked it.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: Now is the time for the question.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: The question is, what was the age of the patient?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Make sure to answer this question in the comment box below.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: I'd eagerly be waiting for your answers.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: And if you like this conversation, then click on the like button.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: And if you want more such conversations like this and haven't subscribed my channel yet, then make sure to click on the subscribe button and share this video with your friends and family.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: That's it for today.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "Sentence: Meet you in the next video with another interesting topic.\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_4.txt\n",
      "Full Text: Hmm. And how old are you?\n",
      "\n",
      "Sentence: And how old are you?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_5.txt\n",
      "Full Text: I'm 29.\n",
      "\n",
      "\n",
      "File: segment_6.txt\n",
      "Full Text: Oops!\n",
      "\n",
      "\n",
      "File: segment_7.txt\n",
      "Full Text: Okay.\n",
      "\n",
      "\n",
      "File: segment_8.txt\n",
      "Full Text: Now tell me, what are the problems that you're facing?\n",
      "\n",
      "Sentence: Now tell me, what are the problems that you're facing?\n",
      "Predicted Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_9.txt\n",
      "Full Text: Since yesterday night I've been having severe stomach ache. I took an antithecid last night but the pain was still the same.\n",
      "\n",
      "Sentence: Since yesterday night I've been having severe stomach ache.\n",
      "Predicted Role: Patient\n",
      "\n",
      "Sentence: I took an antithecid last night but the pain was still the same.\n",
      "Predicted Role: Patient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import re\n",
    "# from transformers import BioGptTokenizer, BioGptForSequenceClassification\n",
    "\n",
    "# # Define model path and transcriptions directory\n",
    "# model_path = r\"D:\\fine_tuned_biogpt\"  # Fine-tuned model saved in D: drive\n",
    "# transcriptions_dir = r\"D:\\whisper_med\\audio_file_patient\\transcriptions\"\n",
    "\n",
    "# # Load fine-tuned BioGPT model and tokenizer\n",
    "# tokenizer = BioGptTokenizer.from_pretrained(model_path)\n",
    "# model = BioGptForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "# model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# def predict_role(text):\n",
    "#     \"\"\"\n",
    "#     Tokenize the input text and predict the role using the fine-tuned model.\n",
    "#     Returns \"Doctor\" if predicted label == 1, else \"Patient\".\n",
    "#     \"\"\"\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "#     inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "#     return \"Doctor\" if predicted_label == 1 else \"Patient\"\n",
    "\n",
    "# def split_sentences(text):\n",
    "#     \"\"\"\n",
    "#     Splits text into sentences based on '.' and '?' delimiters.\n",
    "#     Keeps the delimiters with each sentence.\n",
    "#     \"\"\"\n",
    "#     # Split using regex to retain punctuation as part of sentences.\n",
    "#     sentences = re.split(r'(?<=[.?])\\s+', text)\n",
    "#     sentences = [s.strip() for s in sentences if s.strip()]  # Remove empty strings\n",
    "#     return sentences\n",
    "\n",
    "# # Process each transcribed text file in the directory\n",
    "# for filename in sorted(os.listdir(transcriptions_dir)):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         file_path = os.path.join(transcriptions_dir, filename)\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             full_text = f.read().strip()\n",
    "        \n",
    "#         # Split the full text into sentences based on '.' and '?'\n",
    "#         sentences = split_sentences(full_text)\n",
    "        \n",
    "#         print(f\"\\nFile: {filename}\")\n",
    "#         print(f\"Full Text: {full_text}\\n\")\n",
    "        \n",
    "#         # Predict and print role for each sentence\n",
    "#         for sentence in sentences:\n",
    "#             # Optionally ignore very short sentences if needed\n",
    "#             if len(sentence.split()) < 3:\n",
    "#                 continue\n",
    "#             role = predict_role(sentence)\n",
    "#             print(f\"Sentence: {sentence}\")\n",
    "#             print(f\"Predicted Role: {role}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: segment_0.txt\n",
      "Full Text: May I come in, Doctor? Yes, come in. Take your seat.\n",
      "\n",
      "Sentence: May I come in, Doctor?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Yes, come in.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Take your seat.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_1.txt\n",
      "Full Text: Thank you, doctor. Um, what's your name?\n",
      "\n",
      "Sentence: Thank you, doctor.\n",
      "Model Predicted Role: Doctor --> Final Role: Patient\n",
      "\n",
      "Sentence: Um, what's your name?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_10.txt\n",
      "Full Text: Hmm, any other symptoms?\n",
      "\n",
      "Sentence: Hmm, any other symptoms?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_11.txt\n",
      "Full Text: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "\n",
      "Sentence: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "\n",
      "File: segment_12.txt\n",
      "Full Text: Do you have a headache? No.\n",
      "\n",
      "Sentence: Do you have a headache?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_13.txt\n",
      "Full Text: Did you have this kind of a stomach ache before?\n",
      "\n",
      "Sentence: Did you have this kind of a stomach ache before?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_14.txt\n",
      "Full Text: Yes, doctor. I had it once before.\n",
      "\n",
      "Sentence: I had it once before.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "\n",
      "File: segment_15.txt\n",
      "Full Text: How many days ago?\n",
      "\n",
      "Sentence: How many days ago?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_16.txt\n",
      "Full Text: almost three months ago. But at that time the pain stopped after I took an antacid.\n",
      "\n",
      "Sentence: almost three months ago.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "Sentence: But at that time the pain stopped after I took an antacid.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "\n",
      "File: segment_17.txt\n",
      "Full Text: Hmm. Um, please lie on that bed. I have to check. Okay, doctor.\n",
      "\n",
      "Sentence: Um, please lie on that bed.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: I have to check.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "\n",
      "File: segment_18.txt\n",
      "Full Text: Does it hurt here? Yes, doctor, it hurts a lot. Okay, you can get it now.\n",
      "\n",
      "Sentence: Does it hurt here?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Yes, doctor, it hurts a lot.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Okay, you can get it now.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_19.txt\n",
      "Full Text: Is it something serious, doctor?\n",
      "\n",
      "Sentence: Is it something serious, doctor?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_2.txt\n",
      "Full Text: Simran Parveen.\n",
      "\n",
      "\n",
      "File: segment_20.txt\n",
      "Full Text: I can't say now, I'm writing down some tests. Try to do this by today.\n",
      "\n",
      "Sentence: I can't say now, I'm writing down some tests.\n",
      "Model Predicted Role: Patient --> Final Role: Doctor\n",
      "\n",
      "Sentence: Try to do this by today.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_21.txt\n",
      "Full Text: But what about now? I can't even work properly because of the pain. Hmm, I understand. I'm giving you an injection for temporary relief.\n",
      "\n",
      "Sentence: But what about now?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: I can't even work properly because of the pain.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "Sentence: Hmm, I understand.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "Sentence: I'm giving you an injection for temporary relief.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "\n",
      "File: segment_22.txt\n",
      "Full Text: Injection? Don't you have any medicine?\n",
      "\n",
      "Sentence: Don't you have any medicine?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_23.txt\n",
      "Full Text: Why? Are you scared of injections? It's not like that. I mean, it would be better if you could give me some medicine.\n",
      "\n",
      "Sentence: Are you scared of injections?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: It's not like that.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: I mean, it would be better if you could give me some medicine.\n",
      "Model Predicted Role: Patient --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_24.txt\n",
      "Full Text: Nothing will happen. You won't even feel it. Look at that side.\n",
      "\n",
      "Sentence: Nothing will happen.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: You won't even feel it.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Look at that side.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_25.txt\n",
      "Full Text: Please, doctor, be careful.\n",
      "\n",
      "Sentence: Please, doctor, be careful.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_26.txt\n",
      "Full Text: You can open your eyes now. It's already done.\n",
      "\n",
      "Sentence: You can open your eyes now.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: It's already done.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_27.txt\n",
      "Full Text: Oh, it's done. Thank you so much. I did not feel anything at all.\n",
      "\n",
      "Sentence: Oh, it's done.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Thank you so much.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: I did not feel anything at all.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "\n",
      "File: segment_28.txt\n",
      "Full Text: After receiving the test reports, bring them to me as soon as possible.\n",
      "\n",
      "Sentence: After receiving the test reports, bring them to me as soon as possible.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_29.txt\n",
      "Full Text: There's nothing to fear, right? Don't be so scared beforehand. Let's see the repose first.\n",
      "\n",
      "Sentence: There's nothing to fear, right?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Don't be so scared beforehand.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Let's see the repose first.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_3.txt\n",
      "Full Text: Thank you.\n",
      "\n",
      "\n",
      "File: segment_30.txt\n",
      "Full Text: Won't you give me any medicines doctor? Hmm, I'm prescribing this medicine. It's just for today. Take it after your dinner.\n",
      "\n",
      "Sentence: Won't you give me any medicines doctor?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Hmm, I'm prescribing this medicine.\n",
      "Model Predicted Role: Patient --> Final Role: Doctor\n",
      "\n",
      "Sentence: It's just for today.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Take it after your dinner.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_31.txt\n",
      "Full Text: Okay, doctor. Um, where shall I submit the fees? Please submit that in the cash counter.\n",
      "\n",
      "Sentence: Um, where shall I submit the fees?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Please submit that in the cash counter.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_32.txt\n",
      "Full Text: Thank you, Doctor.\n",
      "\n",
      "Sentence: Thank you, Doctor.\n",
      "Model Predicted Role: Doctor --> Final Role: Patient\n",
      "\n",
      "\n",
      "File: segment_33.txt\n",
      "Full Text: Welcome.\n",
      "\n",
      "\n",
      "File: segment_34.txt\n",
      "Full Text: May I come in, doctor? Oh yes, come in please. Here are the reports of the test that you gave. Oh yeah, let me check them.\n",
      "\n",
      "Sentence: May I come in, doctor?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Oh yes, come in please.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Here are the reports of the test that you gave.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Oh yeah, let me check them.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_35.txt\n",
      "Full Text: I'm sorry.\n",
      "\n",
      "\n",
      "File: segment_36.txt\n",
      "Full Text: Hmm, it's not that serious, nothing to worry about. It was just food poisoning. I'm writing down a medicines, please take them for one week after dinner. Oh, okay doctor. And if you face this problem again, come back immediately. Sure, doctor, thank you. You're welcome.\n",
      "\n",
      "Sentence: Hmm, it's not that serious, nothing to worry about.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: It was just food poisoning.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: I'm writing down a medicines, please take them for one week after dinner.\n",
      "Model Predicted Role: Patient --> Final Role: Doctor\n",
      "\n",
      "Sentence: Oh, okay doctor.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: And if you face this problem again, come back immediately.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "Sentence: Sure, doctor, thank you.\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_4.txt\n",
      "Full Text: Hmm. And how old are you?\n",
      "\n",
      "Sentence: And how old are you?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_5.txt\n",
      "Full Text: I'm 29.\n",
      "\n",
      "\n",
      "File: segment_6.txt\n",
      "Full Text: Oops!\n",
      "\n",
      "\n",
      "File: segment_7.txt\n",
      "Full Text: Okay.\n",
      "\n",
      "\n",
      "File: segment_8.txt\n",
      "Full Text: Now tell me, what are the problems that you're facing?\n",
      "\n",
      "Sentence: Now tell me, what are the problems that you're facing?\n",
      "Model Predicted Role: Doctor --> Final Role: Doctor\n",
      "\n",
      "\n",
      "File: segment_9.txt\n",
      "Full Text: Since yesterday night I've been having severe stomach ache. I took an antithecid last night but the pain was still the same.\n",
      "\n",
      "Sentence: Since yesterday night I've been having severe stomach ache.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n",
      "Sentence: I took an antithecid last night but the pain was still the same.\n",
      "Model Predicted Role: Patient --> Final Role: Patient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# from transformers import BioGptTokenizer, BioGptForSequenceClassification\n",
    "\n",
    "# # Define directories and file paths\n",
    "# model_path = r\"D:\\fine_tuned_biogpt\"  # Fine-tuned model directory\n",
    "# transcriptions_dir = r\"D:\\whisper_med\\audio_file_patient\\transcriptions\"\n",
    "# adaptive_data_path = r\"D:\\whisper_med\\adaptive_training_data.csv\"  # Adaptive training data file\n",
    "\n",
    "# # Load fine-tuned BioGPT model and tokenizer\n",
    "# tokenizer = BioGptTokenizer.from_pretrained(model_path)\n",
    "# model = BioGptForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# def predict_role(text):\n",
    "#     \"\"\"\n",
    "#     Tokenize the input text and predict the role using the fine-tuned model.\n",
    "#     Returns \"Doctor\" if predicted label == 1, else \"Patient\".\n",
    "#     \"\"\"\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "#     inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "#     return \"Doctor\" if predicted_label == 1 else \"Patient\"\n",
    "\n",
    "# def split_sentences(text):\n",
    "#     \"\"\"\n",
    "#     Splits text into sentences based on '.' and '?' delimiters.\n",
    "#     Keeps the delimiters attached.\n",
    "#     \"\"\"\n",
    "#     sentences = re.split(r'(?<=[.?])\\s+', text)\n",
    "#     return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "# # Ensure adaptive training file exists; if not, create it with headers\n",
    "# if not os.path.exists(adaptive_data_path):\n",
    "#     pd.DataFrame(columns=[\"Input\", \"Output\"]).to_csv(adaptive_data_path, index=False)\n",
    "\n",
    "# # Process each transcription file\n",
    "# for filename in sorted(os.listdir(transcriptions_dir)):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         file_path = os.path.join(transcriptions_dir, filename)\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             full_text = f.read().strip()\n",
    "        \n",
    "#         # Split the transcription into fine-grained sentences\n",
    "#         sentences = split_sentences(full_text)\n",
    "        \n",
    "#         print(f\"\\nProcessing File: {filename}\")\n",
    "#         print(f\"Full Text: {full_text}\\n\")\n",
    "        \n",
    "#         for sentence in sentences:\n",
    "#             # Skip very short sentences that might be noise\n",
    "#             if len(sentence.split()) < 3:\n",
    "#                 continue\n",
    "            \n",
    "#             # Predict role using our fine-tuned model\n",
    "#             predicted_role = predict_role(sentence)\n",
    "            \n",
    "#             # If the sentence contains 'doctor' (case-insensitive) and the prediction is \"Doctor\",\n",
    "#             # override the prediction to \"Patient\"\n",
    "#             if re.search(r'\\bdoctor\\b', sentence, flags=re.IGNORECASE) and predicted_role == \"Doctor\":\n",
    "#                 corrected_role = \"Patient\"\n",
    "#                 print(f\"Sentence: {sentence}\")\n",
    "#                 print(f\"Model Predicted Role: {predicted_role}  --> Overridden to: {corrected_role}\")\n",
    "                \n",
    "#                 # Log the corrected example into the adaptive training CSV file\n",
    "#                 new_entry = pd.DataFrame({\"Input\": [sentence], \"Output\": [corrected_role]})\n",
    "#                 new_entry.to_csv(adaptive_data_path, mode='a', header=False, index=False)\n",
    "#             else:\n",
    "#                 corrected_role = predicted_role\n",
    "#                 print(f\"Sentence: {sentence}\")\n",
    "#                 print(f\"Predicted Role: {corrected_role}\")\n",
    "        \n",
    "#         print(\"-\" * 50)\n",
    "\n",
    "# print(f\"\\nAdaptive training data saved at: {adaptive_data_path}\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from transformers import BioGptTokenizer, BioGptForSequenceClassification\n",
    "\n",
    "# Define model path and transcriptions directory\n",
    "model_path = r\"D:\\fine_tuned_biogpt\"  # Fine-tuned model saved in D:\n",
    "transcriptions_dir = r\"D:\\whisper_med\\audio_file_patient\\transcriptions\"\n",
    "adaptive_data_path = r\"D:\\whisper_med\\adaptive_training_data.csv\"  # For adaptive logging (if needed)\n",
    "\n",
    "# Load fine-tuned BioGPT model and tokenizer\n",
    "tokenizer = BioGptTokenizer.from_pretrained(model_path)\n",
    "model = BioGptForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "def predict_role(text):\n",
    "    \"\"\"\n",
    "    Tokenize the input text and predict the role using the fine-tuned model.\n",
    "    Returns \"Doctor\" if predicted label == 1, else \"Patient\".\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return \"Doctor\" if predicted_label == 1 else \"Patient\"\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Splits text into sentences based on '.' and '?' delimiters.\n",
    "    Keeps the delimiters attached.\n",
    "    \"\"\"\n",
    "    # Use regex to split on period or question mark followed by space or end-of-string.\n",
    "    sentences = re.split(r'(?<=[.?])\\s+', text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def apply_generalized_rules(sentence, predicted_role):\n",
    "    \"\"\"\n",
    "    Apply domain-specific rules to override the predicted role based on sentence content.\n",
    "    \n",
    "    Rule 1: If the sentence contains directive/prescription language, override to \"Doctor\".\n",
    "            (e.g., phrases like \"writing down\", \"prescribe\", \"take these medicines\", \"prescribed\")\n",
    "    \n",
    "    Rule 2: If the sentence contains polite address (e.g., \"thank you, doctor\") without directive language,\n",
    "            override to \"Patient\".\n",
    "    \n",
    "    If none match, return the original prediction.\n",
    "    \"\"\"\n",
    "    sentence_lower = sentence.lower()\n",
    "\n",
    "    # Directive keywords (if any of these appear, consider it directive from a doctor)\n",
    "    directive_keywords = [\"writing down\", \"prescribe\", \"prescribing\", \"take these\", \"take them\", \"medicine\", \"medicines\", \"prescribed\"]\n",
    "\n",
    "    # Polite address keyword (often patients address doctors politely)\n",
    "    polite_address_pattern = r'\\bthank you[,]*\\s*doctor\\b'\n",
    "\n",
    "    # Check for directive language\n",
    "    if any(keyword in sentence_lower for keyword in directive_keywords):\n",
    "        return \"Doctor\"\n",
    "    \n",
    "    # Check for polite address\n",
    "    if re.search(polite_address_pattern, sentence_lower):\n",
    "        return \"Patient\"\n",
    "    \n",
    "    return predicted_role\n",
    "\n",
    "# Process each transcription file in the directory\n",
    "for filename in sorted(os.listdir(transcriptions_dir)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(transcriptions_dir, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            full_text = f.read().strip()\n",
    "        \n",
    "        # Split the full text into sentences based on '.' and '?'\n",
    "        sentences = split_sentences(full_text)\n",
    "        \n",
    "        print(f\"\\nFile: {filename}\")\n",
    "        print(f\"Full Text: {full_text}\\n\")\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # Optionally ignore very short sentences\n",
    "            if len(sentence.split()) < 3:\n",
    "                continue\n",
    "            \n",
    "            model_pred = predict_role(sentence)\n",
    "            # Apply our generalized rules\n",
    "            final_pred = apply_generalized_rules(sentence, model_pred)\n",
    "            print(f\"Sentence: {sentence}\")\n",
    "            print(f\"Model Predicted Role: {model_pred} --> Final Role: {final_pred}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing File: name.txt\n",
      "Full Text: Simran Parveen.\n",
      "\n",
      "Sentence: Simran Parveen.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_0.txt\n",
      "Full Text: May I come in, Doctor? Yes, come in. Take your seat.\n",
      "\n",
      "Sentence: May I come in, Doctor?\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: Yes, come in.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Take your seat.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_1.txt\n",
      "Full Text: Thank you, doctor. Um, what's your name?\n",
      "\n",
      "Sentence: Thank you, doctor.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: Um, what's your name?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_10.txt\n",
      "Full Text: Hmm, any other symptoms?\n",
      "\n",
      "Sentence: Hmm, any other symptoms?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_11.txt\n",
      "Full Text: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "\n",
      "Sentence: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_12.txt\n",
      "Full Text: Do you have a headache? No.\n",
      "\n",
      "Sentence: Do you have a headache?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: No.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_13.txt\n",
      "Full Text: Did you have this kind of a stomach ache before?\n",
      "\n",
      "Sentence: Did you have this kind of a stomach ache before?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_14.txt\n",
      "Full Text: Yes, doctor. I had it once before.\n",
      "\n",
      "Sentence: Yes, doctor.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: I had it once before.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_15.txt\n",
      "Full Text: How many days ago?\n",
      "\n",
      "Sentence: How many days ago?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_16.txt\n",
      "Full Text: almost three months ago. But at that time the pain stopped after I took an antacid.\n",
      "\n",
      "Sentence: almost three months ago.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "Sentence: But at that time the pain stopped after I took an antacid.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_17.txt\n",
      "Full Text: Hmm. Um, please lie on that bed. I have to check. Okay, doctor.\n",
      "\n",
      "Sentence: Hmm.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Um, please lie on that bed.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: I have to check.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Okay, doctor.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_18.txt\n",
      "Full Text: Does it hurt here? Yes, doctor, it hurts a lot. Okay, you can get it now.\n",
      "\n",
      "Sentence: Does it hurt here?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Yes, doctor, it hurts a lot.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: Okay, you can get it now.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_19.txt\n",
      "Full Text: Is it something serious, doctor?\n",
      "\n",
      "Sentence: Is it something serious, doctor?\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_20.txt\n",
      "Full Text: I can't say now, I'm writing down some tests. Try to do this by today.\n",
      "\n",
      "Sentence: I can't say now, I'm writing down some tests.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Try to do this by today.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_21.txt\n",
      "Full Text: But what about now? I can't even work properly because of the pain. Hmm, I understand. I'm giving you an injection for temporary relief.\n",
      "\n",
      "Sentence: But what about now?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: I can't even work properly because of the pain.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Hmm, I understand.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "Sentence: I'm giving you an injection for temporary relief.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_22.txt\n",
      "Full Text: Injection? Don't you have any medicine?\n",
      "\n",
      "Sentence: Injection?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Don't you have any medicine?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_23.txt\n",
      "Full Text: Why? Are you scared of injections? It's not like that. I mean, it would be better if you could give me some medicine.\n",
      "\n",
      "Sentence: Why?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Are you scared of injections?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: It's not like that.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: I mean, it would be better if you could give me some medicine.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_24.txt\n",
      "Full Text: Nothing will happen. You won't even feel it. Look at that side.\n",
      "\n",
      "Sentence: Nothing will happen.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: You won't even feel it.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Look at that side.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_25.txt\n",
      "Full Text: Please, doctor, be careful.\n",
      "\n",
      "Sentence: Please, doctor, be careful.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_26.txt\n",
      "Full Text: You can open your eyes now. It's already done.\n",
      "\n",
      "Sentence: You can open your eyes now.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: It's already done.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_27.txt\n",
      "Full Text: Oh, it's done. Thank you so much. I did not feel anything at all.\n",
      "\n",
      "Sentence: Oh, it's done.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Thank you so much.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: I did not feel anything at all.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_28.txt\n",
      "Full Text: After receiving the test reports, bring them to me as soon as possible.\n",
      "\n",
      "Sentence: After receiving the test reports, bring them to me as soon as possible.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_29.txt\n",
      "Full Text: There's nothing to fear, right? Don't be so scared beforehand. Let's see the repose first.\n",
      "\n",
      "Sentence: There's nothing to fear, right?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Don't be so scared beforehand.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Let's see the repose first.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_3.txt\n",
      "Full Text: Thank you.\n",
      "\n",
      "Sentence: Thank you.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_30.txt\n",
      "Full Text: Won't you give me any medicines doctor? Hmm, I'm prescribing this medicine. It's just for today. Take it after your dinner.\n",
      "\n",
      "Sentence: Won't you give me any medicines doctor?\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: Hmm, I'm prescribing this medicine.\n",
      "Model Predicted Role: Patient  --> Final Role: Doctor\n",
      "\n",
      "Sentence: It's just for today.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Take it after your dinner.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_31.txt\n",
      "Full Text: Okay, doctor. Um, where shall I submit the fees? Please submit that in the cash counter.\n",
      "\n",
      "Sentence: Okay, doctor.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: Um, where shall I submit the fees?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Please submit that in the cash counter.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_32.txt\n",
      "Full Text: Thank you, Doctor.\n",
      "\n",
      "Sentence: Thank you, Doctor.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_33.txt\n",
      "Full Text: Welcome.\n",
      "\n",
      "Sentence: Welcome.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_34.txt\n",
      "Full Text: May I come in, doctor? Oh yes, come in please. Here are the reports of the test that you gave. Oh yeah, let me check them.\n",
      "\n",
      "Sentence: May I come in, doctor?\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: Oh yes, come in please.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Here are the reports of the test that you gave.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Oh yeah, let me check them.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_35.txt\n",
      "Full Text: I'm sorry.\n",
      "\n",
      "Sentence: I'm sorry.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_36.txt\n",
      "Full Text: Hmm, it's not that serious, nothing to worry about. It was just food poisoning. I'm writing down a medicines, please take them for one week after dinner. Oh, okay doctor. And if you face this problem again, come back immediately. Sure, doctor, thank you. You're welcome.\n",
      "\n",
      "Sentence: Hmm, it's not that serious, nothing to worry about.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: It was just food poisoning.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: I'm writing down a medicines, please take them for one week after dinner.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "Sentence: Oh, okay doctor.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: And if you face this problem again, come back immediately.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: Sure, doctor, thank you.\n",
      "Model Predicted Role: Doctor  --> Final Role: Patient\n",
      "\n",
      "Sentence: You're welcome.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_4.txt\n",
      "Full Text: Hmm. And how old are you?\n",
      "\n",
      "Sentence: Hmm.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "Sentence: And how old are you?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_5.txt\n",
      "Full Text: I'm 29.\n",
      "\n",
      "Sentence: I'm 29.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Processing File: segment_6.txt\n",
      "Full Text: Oops!\n",
      "\n",
      "Sentence: Oops!\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_7.txt\n",
      "Full Text: Okay.\n",
      "\n",
      "Sentence: Okay.\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_8.txt\n",
      "Full Text: Now tell me, what are the problems that you're facing?\n",
      "\n",
      "Sentence: Now tell me, what are the problems that you're facing?\n",
      "Model Predicted Role: Doctor  --> Final Role: Doctor\n",
      "\n",
      "\n",
      "Processing File: segment_9.txt\n",
      "Full Text: Since yesterday night I've been having severe stomach ache. I took an antithecid last night but the pain was still the same.\n",
      "\n",
      "Sentence: Since yesterday night I've been having severe stomach ache.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "Sentence: I took an antithecid last night but the pain was still the same.\n",
      "Model Predicted Role: Patient  --> Final Role: Patient\n",
      "\n",
      "\n",
      "Adaptive training data saved at: D:\\whisper_med\\adaptive_training_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BioGptTokenizer, BioGptForSequenceClassification\n",
    "\n",
    "# === Directory & Model Setup ===\n",
    "model_path = r\"D:\\fine_tuned_biogpt\"  # Fine-tuned model directory on D:\n",
    "transcriptions_dir = r\"D:\\whisper_med\\audio_file_patient\\transcriptions\"\n",
    "adaptive_data_path = r\"D:\\whisper_med\\adaptive_training_data.csv\"  # Adaptive training data file\n",
    "processed_dir = r\"D:\\whisper_med\\processed_transcriptions\"  # Base folder for saving CSVs\n",
    "\n",
    "# Ensure the adaptive training file exists with proper headers\n",
    "if not os.path.exists(adaptive_data_path):\n",
    "    pd.DataFrame(columns=[\"Input\", \"Output\"]).to_csv(adaptive_data_path, index=False)\n",
    "\n",
    "# Load the fine-tuned BioGPT model and tokenizer\n",
    "tokenizer = BioGptTokenizer.from_pretrained(model_path)\n",
    "model = BioGptForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# === Prediction Function ===\n",
    "def predict_role(text):\n",
    "    \"\"\"\n",
    "    Tokenize the input text and predict the role using the fine-tuned model.\n",
    "    Returns \"Doctor\" if predicted label == 1, else \"Patient\".\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return \"Doctor\" if predicted_label == 1 else \"Patient\"\n",
    "\n",
    "# === Sentence Splitting Function ===\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Splits text into sentences based on '.' and '?' delimiters.\n",
    "    Keeps the punctuation attached.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'(?<=[.?])\\s+', text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "# # === Updated Rule-Based Correction Function ===\n",
    "# def apply_rule_based_corrections(text, predicted_role):\n",
    "#     \"\"\"\n",
    "#     Applies the updated rule-based corrections to the model's prediction.\n",
    "#     Rules (applied in order):\n",
    "    \n",
    "#     1. Polite Address Rule (Highest Priority):\n",
    "#        - If the sentence contains polite address indicators (e.g., \"thank you, doctor\", \"may i come in, doctor\", \"hi doctor\")\n",
    "#          then override the prediction to Patient.\n",
    "         \n",
    "#     2. Directive Language vs. Request Context:\n",
    "#        - If the sentence contains directive keywords (e.g., \"writing down\", \"prescribe\", \"take these\", \"medicine\", \"medicines\", \"prescribed\"):\n",
    "#          â€¢ If it does NOT contain any request indicators (e.g., \"could you\", \"would you\", \"can you\", \"please\", \"won't you\", \"should i\", \"is it okay if i\", \"will you\", \"can i\"),\n",
    "#            override the prediction to Doctor.\n",
    "#          â€¢ If it DOES contain request phrases, override to Patient.\n",
    "         \n",
    "#     3. Age Information Rule:\n",
    "#        - If the sentence mentions age (e.g., \"I'm 29\", \"I am 29\", \"my age is 29\"), override the prediction to Patient.\n",
    "       \n",
    "#     4. Unlabeled Default:\n",
    "#        - If the model's prediction is empty or \"Unlabeled\", default to Patient.\n",
    "    \n",
    "#     If none of these rules apply, return the model's prediction.\n",
    "#     \"\"\"\n",
    "#     # If no prediction, default to \"Unlabeled\"\n",
    "#     if not predicted_role or predicted_role.strip() == \"\":\n",
    "#         predicted_role = \"Unlabeled\"\n",
    "    \n",
    "#     text_lower = text.lower()\n",
    "\n",
    "#     # Rule 1: Polite Address Rule â€“ override to Patient\n",
    "#     polite_patterns = [r'\\bthank you[,]*\\s*doctor\\b', r'\\bmay i come\\b', r'\\bhi doctor\\b']\n",
    "#     for pattern in polite_patterns:\n",
    "#         if re.search(pattern, text_lower):\n",
    "#             if predicted_role != \"Patient\":\n",
    "#                 return \"Patient\", True\n",
    "#             return \"Patient\", False\n",
    "\n",
    "#     # Rule 2: Directive Language vs. Request Context\n",
    "#     directive_keywords = [\"writing down\", \"prescribe\", \"prescribing\", \"take these\", \"take them\", \"medicine\", \"medicines\", \"prescribed\"]\n",
    "#     request_phrases = [\"could you\", \"would you\", \"can you\", \"please\", \"won't you\", \"should i\", \"is it okay if i\", \"will you\", \"can i\"]\n",
    "#     has_directive = any(keyword in text_lower for keyword in directive_keywords)\n",
    "#     has_request = any(phrase in text_lower for phrase in request_phrases)\n",
    "\n",
    "#     if has_directive:\n",
    "#         if has_request:\n",
    "#             if predicted_role != \"Patient\":\n",
    "#                 return \"Patient\", True\n",
    "#             return \"Patient\", False\n",
    "#         else:\n",
    "#             if predicted_role != \"Doctor\":\n",
    "#                 return \"Doctor\", True\n",
    "#             return \"Doctor\", False\n",
    "\n",
    "#     # Rule 3: Age Information Rule â€“ override to Patient\n",
    "#     age_pattern = r\"(?:i'?m|i am|my age is)\\s*\\d{1,3}\"\n",
    "#     if re.search(age_pattern, text_lower):\n",
    "#         if predicted_role != \"Patient\":\n",
    "#             return \"Patient\", True\n",
    "#         return \"Patient\", False\n",
    "\n",
    "#     # Rule 4: If model prediction is Unlabeled, default to Patient.\n",
    "#     if predicted_role == \"Unlabeled\":\n",
    "#         return \"Patient\", True\n",
    "\n",
    "#     # If no rule applies, return the model's prediction.\n",
    "#     return predicted_role, False\n",
    "\n",
    "# === Logging Function for Reinforcement Learning ===\n",
    "def log_correction(sentence, corrected_label):\n",
    "    \"\"\"\n",
    "    Append the corrected example (sentence and corrected label) to the adaptive training CSV file.\n",
    "    \"\"\"\n",
    "    new_entry = pd.DataFrame({\"Input\": [sentence], \"Output\": [corrected_label]})\n",
    "    new_entry.to_csv(adaptive_data_path, mode='a', header=False, index=False)\n",
    "\n",
    "# === Function to Save Results into CSV Files ===\n",
    "def save_results(filename, sentence, role):\n",
    "    \"\"\"\n",
    "    Saves processed sentences into their respective CSV files (doctor.csv or patient.csv)\n",
    "    in a folder named after the original transcription file (without extension) under:\n",
    "    D:\\whisper_med\\processed_transcriptions\n",
    "    \"\"\"\n",
    "    base_dir = r\"D:\\whisper_med\\processed_transcriptions\"\n",
    "    folder_name = os.path.splitext(filename)[0]\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    file_path = os.path.join(folder_path, f\"{role.lower()}.csv\")\n",
    "    new_entry = pd.DataFrame({\"Sentence\": [sentence]})\n",
    "    new_entry.to_csv(file_path, mode=\"a\", header=not os.path.exists(file_path), index=False)\n",
    "\n",
    "# === Context-Aware Rule-Based Correction Function ===\n",
    "def apply_rule_based_corrections(text, predicted_role, prev_text=None, prev_role=None):\n",
    "    \"\"\"\n",
    "    Applies rule-based corrections with dynamic context awareness.\n",
    "    \n",
    "    - `prev_text`: The previous sentence (for context-based decisions).\n",
    "    - `prev_role`: The role assigned to the previous sentence.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Rule 1: If \"doctor\" is present in the sentence, label as \"Patient\"\n",
    "    if \"doctor\" in text_lower:\n",
    "        return \"Patient\", True  # Override applied\n",
    "\n",
    "    # Rule 2: Directive Language (Doctors giving instructions)\n",
    "    directive_keywords = [\"writing down\", \"prescribe\", \"prescribing\", \"take these\", \"take them\", \"medicine\", \"medicines\", \"prescribed\"]\n",
    "    request_phrases = [\"could you\", \"would you\", \"can you\", \"please\", \"won't you\", \"should I\", \"is it okay if I\", \"will you\", \"can I\"]\n",
    "    has_directive = any(keyword in text_lower for keyword in directive_keywords)\n",
    "    has_request = any(phrase in text_lower for phrase in request_phrases)\n",
    "\n",
    "    if has_directive:\n",
    "        return (\"Patient\", True) if has_request else (\"Doctor\", True)\n",
    "\n",
    "    # Rule 3: Age Information (Sentences mentioning age â†’ Patient)\n",
    "    age_pattern = r\"(?:i'?m|i am|my age is)\\s*\\d{1,3}\"\n",
    "    if re.search(age_pattern, text_lower):\n",
    "        return \"Patient\", True\n",
    "\n",
    "    # Rule 4: Context Window (If previous sentence was from a doctor, continue as Doctor)\n",
    "    if prev_text and prev_role == \"Doctor\":\n",
    "        return \"Doctor\", True\n",
    "\n",
    "    # Rule 5: Default to Modelâ€™s Prediction (if no rules apply)\n",
    "    return predicted_role, False\n",
    "\n",
    "\n",
    "# === Modified Main Processing Loop with Context Awareness ===\n",
    "for filename in sorted(os.listdir(transcriptions_dir)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(transcriptions_dir, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            full_text = f.read().strip()\n",
    "        \n",
    "        sentences = split_sentences(full_text)\n",
    "\n",
    "        print(f\"\\nProcessing File: {filename}\")\n",
    "        print(f\"Full Text: {full_text}\\n\")\n",
    "\n",
    "        prev_sentence = None\n",
    "        prev_role = None\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if len(sentence.split()) < 1:\n",
    "                continue  # Skip empty sentences\n",
    "\n",
    "            model_pred = predict_role(sentence)\n",
    "            final_role, overridden = apply_rule_based_corrections(sentence, model_pred, prev_sentence, prev_role)\n",
    "\n",
    "            print(f\"Sentence: {sentence}\")\n",
    "            print(f\"Model Predicted Role: {model_pred}  --> Final Role: {final_role}\\n\")\n",
    "\n",
    "            if overridden:\n",
    "                log_correction(sentence, final_role)\n",
    "\n",
    "            save_results(filename, sentence, final_role)\n",
    "\n",
    "            # Update context for next iteration\n",
    "            prev_sentence = sentence\n",
    "            prev_role = final_role\n",
    "print(f\"\\nAdaptive training data saved at: {adaptive_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# Define the model path (the directory where the model is downloaded)\n",
    "model_path = r\"C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--Clinical-AI-Apollo--Medical-NER\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Create a NER pipeline using the loaded model and tokenizer\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# Example: Process a transcribed text segment\n",
    "sample_text = (\n",
    "    \"Patient says: I'm 29 and I've been experiencing headaches for the last few days. \"\n",
    "    \"Doctor prescribed 500mg of paracetamol to be taken twice a day.\"\n",
    ")\n",
    "\n",
    "# Run the NER pipeline on the sample text\n",
    "entities = ner_pipeline(sample_text)\n",
    "\n",
    "# Print out the extracted entities\n",
    "print(\"Extracted Medical Entities:\")\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Score: {entity['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing folder: name\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Simran Parveen.\n",
      "NER Output: [{'entity_group': 'Age', 'score': 0.06272781, 'word': 'Simran', 'start': 0, 'end': 6}]\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_0\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yes, come in.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Take your seat.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: May I come in, Doctor?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_1\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Um, what's your name?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Thank you, doctor.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_10\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Hmm, any other symptoms?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_11\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yeah, I also had bouts of vomiting last night and today morning as well.\n",
      "NER Output: [{'entity_group': 'Sign_symptom', 'score': 0.20863366, 'word': 'vomiting', 'start': 25, 'end': 34}, {'entity_group': 'Date', 'score': 0.20515616, 'word': 'night', 'start': 39, 'end': 45}, {'entity_group': 'Date', 'score': 0.14541103, 'word': 'morning', 'start': 55, 'end': 63}]\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_12\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Do you have a headache?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: No.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_13\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Did you have this kind of a stomach ache before?\n",
      "NER Output: [{'entity_group': 'Disease_disorder', 'score': 0.14776263, 'word': 'stomach', 'start': 27, 'end': 35}]\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_14\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yes, doctor.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: I had it once before.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_15\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: How many days ago?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_16\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: almost three months ago.\n",
      "NER Output: [{'entity_group': 'Duration', 'score': 0.15342881, 'word': 'three', 'start': 6, 'end': 12}, {'entity_group': 'Duration', 'score': 0.10232926, 'word': 'months', 'start': 12, 'end': 19}]\n",
      "----------------------------------------\n",
      "Sentence: But at that time the pain stopped after I took an antacid.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_17\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Hmm.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Um, please lie on that bed.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: I have to check.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Okay, doctor.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_18\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Does it hurt here?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Okay, you can get it now.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yes, doctor, it hurts a lot.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_19\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Is it something serious, doctor?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_20\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I can't say now, I'm writing down some tests.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Try to do this by today.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_21\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: But what about now?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: I can't even work properly because of the pain.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Hmm, I understand.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: I'm giving you an injection for temporary relief.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_22\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Injection?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Don't you have any medicine?\n",
      "NER Output: [{'entity_group': 'History', 'score': 0.27738333, 'word': 'medicine?', 'start': 18, 'end': 28}]\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_23\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Why?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Are you scared of injections?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: It's not like that.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: I mean, it would be better if you could give me some medicine.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_24\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Nothing will happen.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: You won't even feel it.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Look at that side.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_25\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Please, doctor, be careful.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_26\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: You can open your eyes now.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: It's already done.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_27\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Oh, it's done.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Thank you so much.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: I did not feel anything at all.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_28\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: After receiving the test reports, bring them to me as soon as possible.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_29\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: There's nothing to fear, right?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Don't be so scared beforehand.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Let's see the repose first.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_3\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Thank you.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_30\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Hmm, I'm prescribing this medicine.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: It's just for today.\n",
      "NER Output: [{'entity_group': 'Detailed_description', 'score': 0.11374801, 'word': 'just', 'start': 4, 'end': 9}]\n",
      "----------------------------------------\n",
      "Sentence: Take it after your dinner.\n",
      "NER Output: [{'entity_group': 'Detailed_description', 'score': 0.09271472, 'word': 'after', 'start': 7, 'end': 13}]\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Won't you give me any medicines doctor?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_31\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Um, where shall I submit the fees?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Please submit that in the cash counter.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Okay, doctor.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_32\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Thank you, Doctor.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_33\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Welcome.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_34\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Oh yes, come in please.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Here are the reports of the test that you gave.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Oh yeah, let me check them.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: May I come in, doctor?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_35\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I'm sorry.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_36\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Hmm, it's not that serious, nothing to worry about.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: It was just food poisoning.\n",
      "NER Output: [{'entity_group': 'Disease_disorder', 'score': 0.3556828, 'word': 'food', 'start': 11, 'end': 16}]\n",
      "----------------------------------------\n",
      "Sentence: And if you face this problem again, come back immediately.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: You're welcome.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I'm writing down a medicines, please take them for one week after dinner.\n",
      "NER Output: [{'entity_group': 'Duration', 'score': 0.31108415, 'word': 'one', 'start': 50, 'end': 54}, {'entity_group': 'Duration', 'score': 0.46910623, 'word': 'week', 'start': 54, 'end': 59}, {'entity_group': 'Duration', 'score': 0.13263787, 'word': 'after', 'start': 59, 'end': 65}]\n",
      "----------------------------------------\n",
      "Sentence: Oh, okay doctor.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: Sure, doctor, thank you.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_4\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Hmm.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "Sentence: And how old are you?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_5\n",
      "\n",
      "Processing file: patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I'm 29.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_6\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Oops!\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_7\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Okay.\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_8\n",
      "\n",
      "Processing file: doctor.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Now tell me, what are the problems that you're facing?\n",
      "NER Output: []\n",
      "----------------------------------------\n",
      "\n",
      "Processing folder: segment_9\n",
      "\n",
      "Processing file: patient.csv\n",
      "Sentence: Since yesterday night I've been having severe stomach ache.\n",
      "NER Output: [{'entity_group': 'Date', 'score': 0.31920394, 'word': 'yesterdaynight', 'start': 5, 'end': 21}, {'entity_group': 'Severity', 'score': 0.49358055, 'word': 'severe', 'start': 38, 'end': 45}, {'entity_group': 'Sign_symptom', 'score': 0.23591548, 'word': 'stomach', 'start': 45, 'end': 53}]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I took an antithecid last night but the pain was still the same.\n",
      "NER Output: [{'entity_group': 'Medication', 'score': 0.6232004, 'word': 'antithecid', 'start': 9, 'end': 20}, {'entity_group': 'Date', 'score': 0.19697075, 'word': 'night', 'start': 25, 'end': 31}]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# --- Setup: Define the base processed transcription directory and model path ---\n",
    "\n",
    "processed_dir = r\"D:\\whisper_med\\processed_transcriptions\"  # Folder containing segment sub-folders\n",
    "med_ner_model_path = \"Helios9/BIOMed_NER\"  # Model path for Clinical AI Apollo Med NER\n",
    "\n",
    "# --- Load the Med NER Pipeline ---\n",
    "ner_pipe = pipeline(\n",
    "    task=\"token-classification\",\n",
    "    model=med_ner_model_path,\n",
    "    tokenizer=med_ner_model_path,\n",
    "    aggregation_strategy=\"average\"\n",
    ")\n",
    "\n",
    "# --- Process all CSV files in the segments folder ---\n",
    "# This will iterate over each sub-folder (e.g., segment_0, segment_1, etc.)\n",
    "for segment_folder in sorted(os.listdir(processed_dir)):\n",
    "    folder_path = os.path.join(processed_dir, segment_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"\\nProcessing folder: {segment_folder}\")\n",
    "        # Process each CSV file in the sub-folder\n",
    "        for file in sorted(os.listdir(folder_path)):\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_path = os.path.join(folder_path, file)\n",
    "                print(f\"\\nProcessing file: {file}\")\n",
    "                df = pd.read_csv(csv_path)\n",
    "                \n",
    "                # Check if there is a 'Sentence' column\n",
    "                if \"Sentence\" not in df.columns:\n",
    "                    print(f\"Column 'Sentence' not found in {file}. Skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                # Process each sentence using the NER pipeline\n",
    "                for idx, row in df.iterrows():\n",
    "                    sentence = row[\"Sentence\"]\n",
    "                    ner_output = ner_pipe(sentence)\n",
    "                    print(f\"Sentence: {sentence}\")\n",
    "                    print(\"NER Output:\", ner_output)\n",
    "                    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164a1c257e6e4ebc9827ed0f723d1cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--d4data--biomedical-ner-all. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac292a06e9141a28898a20dc33f8779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397f52ce00f042cd889f195ed1f172ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832ca8a836954aae8b88be2cdd37d7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1c4a21d73f455ba760563768ae929d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/5.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe1abd26f4147e6810d43515912d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/266M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\Bio_Epidemiology_NER\\bio_recognizer.py:94: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(disease_df) # adding the disease_df to existing\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\Bio_Epidemiology_NER\\bio_recognizer.py:100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  master_df = master_df.append(final_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           entity_group                                              value  \\\n",
      "0                   Sex                                              woman   \n",
      "1                   Age                                    age of 65 years   \n",
      "2          Sign_symptom                                              fever   \n",
      "3          Sign_symptom                                          shivering   \n",
      "4  Biological_structure                                               legs   \n",
      "5              Duration                                         two months   \n",
      "6             Frequency  nearly 2 to 3 times facing shivering in in wom...   \n",
      "\n",
      "      score  \n",
      "0  0.999641  \n",
      "1  0.986176  \n",
      "2  0.999828  \n",
      "3  0.999826  \n",
      "4  0.999890  \n",
      "5  0.996540  \n",
      "6  0.924235  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6bdb2587ca4c26bc04705f7431975f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--medicalai--ClinicalBERT. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5247c60463eb40ec827253a365c3f976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e7d4ba534040b98831d4062737db04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98a58150b844f60810fc0ff14503505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bc85576c594ba2a58c3f6e1625ca6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e989e2abd0d7408689929f52b741c34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# # Load the model\n",
    "# model_path = \"Helios9/BIOMed_NER\"\n",
    "# pipe = pipeline(\n",
    "#     task=\"token-classification\",\n",
    "#     model=model_path,\n",
    "#     tokenizer=model_path,\n",
    "#     aggregation_strategy=\"max\"\n",
    "# )\n",
    "\n",
    "# # Test the pipeline\n",
    "# text = (\"A 48-year-old female presented with vaginal bleeding and abnormal Pap smears. \"\n",
    "#         \"Upon diagnosis of invasive non-keratinizing SCC of the cervix, she underwent a radical \"\n",
    "#         \"hysterectomy with salpingo-oophorectomy which demonstrated positive spread to the pelvic \"\n",
    "#         \"lymph nodes and the parametrium.\")\n",
    "# result = pipe(text)\n",
    "# print(result)\n",
    "\n",
    "from Bio_Epidemiology_NER.bio_recognizer import ner_prediction\n",
    "\n",
    "# returns the predicted class along with the probability of the actual EnvBert model\n",
    "doc = \"\"\"\n",
    "\tCASE: A woman with age of 65 years facing a headache, fever and shivering in legs\n",
    "      for last two months and this occurs nearly 2 to 3 times in a week\n",
    "      \"\"\"\n",
    "\n",
    "# returns a dataframe output\n",
    "print(ner_prediction(corpus=doc, compute='gpu')) #pass compute='gpu' if using gpu\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"medicalai/ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER results for D:\\whisper_med\\processed_transcriptions\\doctor_merged.csv:\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.50863206, 'word': 'stomachache', 'start': 177, 'end': 190}\n",
      "{'entity_group': 'Duration', 'score': 0.34032366, 'word': 'days', 'start': 216, 'end': 221}\n",
      "{'entity_group': 'Therapeutic_procedure', 'score': 0.4825295, 'word': 'injection', 'start': 533, 'end': 543}\n",
      "{'entity_group': 'Disease_disorder', 'score': 0.6709282, 'word': 'food', 'start': 1448, 'end': 1453}\n",
      "NER results for D:\\whisper_med\\processed_transcriptions\\patient_merged.csv:\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.88265896, 'word': 'vomiting', 'start': 119, 'end': 128}\n",
      "{'entity_group': 'Duration', 'score': 0.14955811, 'word': 'night', 'start': 133, 'end': 139}\n",
      "{'entity_group': 'Date', 'score': 0.19101742, 'word': 'todaymorning', 'start': 143, 'end': 157}\n",
      "{'entity_group': 'Date', 'score': 0.48064843, 'word': 'threemonths', 'start': 226, 'end': 239}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.66078514, 'word': 'pain', 'start': 265, 'end': 270}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.46912268, 'word': 'hurts', 'start': 351, 'end': 357}\n",
      "{'entity_group': 'Duration', 'score': 0.35437098, 'word': 'one', 'start': 730, 'end': 734}\n",
      "{'entity_group': 'Duration', 'score': 0.6291565, 'word': 'week', 'start': 734, 'end': 739}\n",
      "{'entity_group': 'Date', 'score': 0.40514797, 'word': 'yesterdaynight', 'start': 827, 'end': 843}\n",
      "{'entity_group': 'Severity', 'score': 0.5520593, 'word': 'severe', 'start': 860, 'end': 867}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.67872417, 'word': 'stomach', 'start': 867, 'end': 875}\n",
      "{'entity_group': 'Medication', 'score': 0.96821636, 'word': 'antithecid', 'start': 891, 'end': 902}\n",
      "{'entity_group': 'Date', 'score': 0.55719525, 'word': 'night', 'start': 907, 'end': 913}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.63696104, 'word': 'pain', 'start': 921, 'end': 926}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define directory where segmented CSVs are stored\n",
    "base_dir = r\"D:\\whisper_med\\processed_transcriptions\"\n",
    "\n",
    "def merge_csvs(role):\n",
    "    merged_data = []\n",
    "    \n",
    "    # Iterate over all segment folders\n",
    "    for folder in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith(f\"{role}.csv\"):  # Match only the role-specific files\n",
    "                    file_path = os.path.join(folder_path, file)\n",
    "                    df = pd.read_csv(file_path, header=None)  # Read without assuming headers\n",
    "                    merged_data.append(df)\n",
    "    \n",
    "    if merged_data:\n",
    "        merged_df = pd.concat(merged_data, ignore_index=True)\n",
    "        merged_file = os.path.join(base_dir, f\"{role}_merged.csv\")\n",
    "        merged_df.to_csv(merged_file, index=False, header=False)  # Save without headers\n",
    "        return merged_file\n",
    "    else:\n",
    "        print(f\"No files found for role: {role}\")\n",
    "        return None\n",
    "\n",
    "# Merge CSVs for doctors and patients\n",
    "doctor_csv = merge_csvs(\"doctor\")\n",
    "patient_csv = merge_csvs(\"patient\")\n",
    "\n",
    "# Load Helios9/BIOMed_NER model\n",
    "model_path = \"Helios9/BIOMed_NER\"\n",
    "ner_pipeline = pipeline(task=\"token-classification\", model=model_path, tokenizer=model_path, aggregation_strategy=\"max\")\n",
    "\n",
    "def run_ner_on_csv(csv_file):\n",
    "    if csv_file is None:\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    full_text = \" \".join(df[0].astype(str))  # Merge all sentences into one text\n",
    "    result = ner_pipeline(full_text)\n",
    "    \n",
    "    print(f\"NER results for {csv_file}:\")\n",
    "    for entity in result:\n",
    "        print(entity)\n",
    "\n",
    "# Run NER on merged doctor and patient CSVs\n",
    "run_ner_on_csv(doctor_csv)\n",
    "run_ner_on_csv(patient_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved NER results to D:\\whisper_med\\processed_transcriptions\\doctor_ner_results.csv\n",
      "Saved NER results to D:\\whisper_med\\processed_transcriptions\\patient_ner_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define directory where segmented CSVs are stored\n",
    "base_dir = r\"D:\\whisper_med\\processed_transcriptions\"\n",
    "\n",
    "# Function to merge CSVs for a given role\n",
    "def merge_csvs(role):\n",
    "    merged_data = []\n",
    "    \n",
    "    for folder in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith(f\"{role}.csv\"):\n",
    "                    file_path = os.path.join(folder_path, file)\n",
    "                    df = pd.read_csv(file_path, header=None)\n",
    "                    merged_data.append(df)\n",
    "    \n",
    "    if merged_data:\n",
    "        merged_df = pd.concat(merged_data, ignore_index=True)\n",
    "        merged_file = os.path.join(base_dir, f\"{role}_merged.csv\")\n",
    "        merged_df.to_csv(merged_file, index=False, header=False)\n",
    "        return merged_file\n",
    "    return None\n",
    "\n",
    "# Merge CSVs for doctors and patients\n",
    "doctor_csv = merge_csvs(\"doctor\")\n",
    "patient_csv = merge_csvs(\"patient\")\n",
    "\n",
    "# Load Helios9/BIOMed_NER model\n",
    "model_path = \"Helios9/BIOMed_NER\"\n",
    "ner_pipeline = pipeline(task=\"token-classification\", model=model_path, tokenizer=model_path, aggregation_strategy=\"average\")\n",
    "\n",
    "# Function to extract and group NER entities\n",
    "def extract_and_group_entities(csv_file, output_file):\n",
    "    if csv_file is None:\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    full_text = \" \".join(df[0].astype(str))\n",
    "    ner_results = ner_pipeline(full_text)\n",
    "    \n",
    "    # Group entities\n",
    "    grouped_entities = {\"Sign/Symptoms\": [], \"Predicted Diseases\": [], \"Duration\": [], \"Medication\": []}\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        entity_text = entity['word']\n",
    "        entity_group = entity['entity_group'].lower()\n",
    "        \n",
    "        if \"symptom\" in entity_group:\n",
    "            grouped_entities[\"Sign/Symptoms\"].append(entity_text)\n",
    "        elif \"disease\" in entity_group:\n",
    "            grouped_entities[\"Predicted Diseases\"].append(entity_text)\n",
    "        elif \"duration\" in entity_group:\n",
    "            grouped_entities[\"Duration\"].append(entity_text)\n",
    "        elif \"medication\" in entity_group:\n",
    "            grouped_entities[\"Medication\"].append(entity_text)\n",
    "    \n",
    "    # Save results to CSV\n",
    "    grouped_df = pd.DataFrame([grouped_entities])\n",
    "    grouped_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved NER results to {output_file}\")\n",
    "\n",
    "# Run NER and save structured results\n",
    "extract_and_group_entities(doctor_csv, os.path.join(base_dir, \"doctor_ner_results.csv\"))\n",
    "extract_and_group_entities(patient_csv, os.path.join(base_dir, \"patient_ner_results.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
